{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b9532b7",
   "metadata": {},
   "source": [
    "# <font color='darkred'>Tese de Mestrado</font>\n",
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b515b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lightgbm as lgb\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06580f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('df_final.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca70ce3f-b300-4151-affd-a259ed33fb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba2583-61af-4038-8218-3e2e74832580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c717befa-8232-4cb8-947f-97bac18322cf",
   "metadata": {},
   "source": [
    "#### <font color='darkred'>Tratamento</font>\n",
    "#### Identificação dos Valores Omissose Substiuição po NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39650f-e0b3-45d3-a89d-2f6066001332",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_omissos = df.isna().sum().sum()\n",
    "print(\"\\nNúmero total de valores omissos no DataFrame:\", total_omissos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3968b5c-a4af-4b4c-be72-172064575935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituição dos valores omissos por NA\n",
    "df.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63e243a-da9a-438f-a181-7929e524ed86",
   "metadata": {},
   "source": [
    "#### 11 Anos no Privado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f5b419-e91a-4d56-8d1d-999371848649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0048e5d5-2388-4f49-9bd1-4f19ab7cb91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado = df_filtrado[~df_filtrado.apply(lambda row: row.astype(str).str.contains('Não Trabalhou').any(), axis=1)]\n",
    "df_filtrado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfdaef5-bd44-4416-828f-9452df633fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_omissos = df_filtrado.isna().sum().sum()\n",
    "print(\"\\nNúmero total de valores omissos no DataFrame:\", total_omissos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f327fc92-fc56-42bd-9038-1890d3a34b21",
   "metadata": {},
   "source": [
    "- A percentagem de pessoas que estão há 11 anos no privado é aproximadamente 29,73% da amostra em análise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53a91bc-46af-4755-9aef-fa8936ec4b83",
   "metadata": {},
   "source": [
    "#### Categorias \"Ignorada\"\n",
    "É sabido que nas variáveis tipo_contr, habil e prof_3d existe a categoria \"Ignorada\". Tendo em consideração que se tratam de variáveis ordinais e que serão utilizadas desta forma no Modelo de Regressão Logística, averiguar-se-á se estas categorias efetivamente existem na amostra selecionada. \n",
    "- Variável tipo_contr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef06b321-b021-4ddf-9ad9-f84db7cb8af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_contr1_columns = [col for col in df_filtrado.columns if col.startswith('tipo_contr1')]\n",
    "unique_values_set = set()\n",
    "\n",
    "for col in tipo_contr1_columns:\n",
    "    unique_values_set.update(df_filtrado[col].unique())\n",
    "\n",
    "contains_8 = 8 in unique_values_set\n",
    "print(f\"O valor 8 (Ignorada) está presente nas colunas 'tipo_contr1': {contains_8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e949a59-df28-40ba-8e65-b730c8871df1",
   "metadata": {},
   "source": [
    "- Variável habil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3caab1-9daa-46b0-b40f-46e85658fe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "habil_columns = [col for col in df_filtrado.columns if col.startswith('habil1')]\n",
    "unique_values_set = set()\n",
    "\n",
    "for col in habil_columns:\n",
    "    unique_values_set.update(df_filtrado[col].unique())\n",
    "\n",
    "contains_9 = 9 in unique_values_set\n",
    "print(f\"O valor 9 (Ignorada) está presente nas colunas 'habil1': {contains_9}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c3f01-5990-4fed-8698-8bee19cb0792",
   "metadata": {},
   "source": [
    "- Variável prof_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c5605-7b87-4546-bd68-e977206d32f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_3d_columns = [col for col in df_filtrado.columns if col.startswith('prof_3d_')]\n",
    "unique_values_set = set()\n",
    "\n",
    "for col in prof_3d_columns:\n",
    "    unique_values_set.update(df_filtrado[col].unique())\n",
    "\n",
    "contains_9999 = 9999 in unique_values_set\n",
    "print(f\"O valor 9999 (Ignorada) está presente nas colunas 'prof_3d': {contains_9999}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b461d5-dbf6-495a-9b2f-dc4b49ed5363",
   "metadata": {},
   "source": [
    "Tendo em consideração que todas as variáveis têm esta categoria, proceder-se-á à eliminação destes trabalhadores, por forma a não enviesar os resultados.\n",
    "- Eliminação dos Trabalhadores que contém esta categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9fbdde-6a0c-49fd-b5fa-6b65ab6a29c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Nº de \"Ignorada\" em cada coluna\n",
    "ignorado_valores = {\n",
    "    'habil1': [9],\n",
    "    'tipo_contr1': [8],\n",
    "    'prof_3d': [9999]\n",
    "}\n",
    "\n",
    "for var, valores in ignorado_valores.items():\n",
    "    for ano in range(9, 20):\n",
    "        col = f'{var}_{ano:02d}'\n",
    "        if col in df_filtrado.columns:\n",
    "            ignorados = df_filtrado[col].isin(valores).sum()\n",
    "            print(f'{col} - Valores Ignorados ({valores}): {ignorados}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552453ba-34d9-4eea-9fa3-21d49db7f6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trab_filtrada = df_filtrado.copy()\n",
    "\n",
    "for var, valores in ignorado_valores.items():\n",
    "    for ano in range(9, 20):\n",
    "        col = f'{var}_{ano:02d}'\n",
    "        if col in df_trab_filtrada.columns:\n",
    "            df_trab_filtrada = df_trab_filtrada[~df_trab_filtrada[col].isin(valores)]\n",
    "\n",
    "print(f\"Dimensões do DataFrame após remoção: {df_trab_filtrada.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e28d3d6-573a-44af-b74a-2725f00f3f87",
   "metadata": {},
   "source": [
    "Após este tratamento, foi eliminada 6,49% da amostra considerada para este modelo, tendo no final, 50 778 trabalhadores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca75a3c2-9163-419c-95f4-6ebc2a619ea0",
   "metadata": {},
   "source": [
    "#### Correção de Na's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b082e56-0db8-4359-a46f-18371699b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_ausentes = df_trab_filtrada.isna().sum()\n",
    "colunas_com_na = valores_ausentes[valores_ausentes > 0]\n",
    "colunas_com_na"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d5a953-ade7-425e-9383-f7fa33cb0419",
   "metadata": {},
   "source": [
    "- Das colunas de interesse para o Modelo, apenas a variável rganho tem valores omissos. Tendo em consideração que são apenas 4, será feita a substituição deste pelo último valor rganho com informação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3055909-0be8-428e-9855-2c0709f73902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher valores ausentes no 'rganho' com o valor do ano anterior\n",
    "for ano in range(10, 20):\n",
    "    col_atual = f'rganho_h_{ano:02d}'\n",
    "    col_anterior = f'rganho_h_{ano - 1:02d}'\n",
    "    df_trab_filtrada[col_atual] = df_trab_filtrada[col_atual].fillna(df_trab_filtrada[col_anterior])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b5644-f79a-4556-b653-11fbc7db0cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trab_filtrada[[f'rganho_h_{ano:02d}' for ano in range(10, 20)]].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af47d99f-267e-407a-89a4-e8b7c9882f9e",
   "metadata": {},
   "source": [
    "#### Mudança de Emprego\n",
    "Criação de colunas que indicam se ocorreu ou não troca de emprego do ano n face ao ano n-1\n",
    "- Se ambos os valores de nuemp para os dois anos são NaN, retorna False porque não há dados suficientes para determinar uma mudança de emprego.\n",
    "- Se pelo menos um dos valores de nuemp é NaN, retorna False porque a comparação entre um valor conhecido e um valor ausente não pode determinar com certeza se houve uma mudança de emprego.\n",
    "- Verifica se os valores de nuemp para os dois anos são diferentes. Se os valores são diferentes, retorna True, indicando que houve uma mudança de emprego entre os dois anos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f43524-e153-4a83-a668-8747093b6a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emp = df_trab_filtrada.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc0f2d4-6991-4475-af49-ec2c5af21ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica_mudanca_emprego(nuemp_ano1, nuemp_ano2):\n",
    "    if pd.isna(nuemp_ano1) and pd.isna(nuemp_ano2):\n",
    "        return False\n",
    "    if pd.isna(nuemp_ano1) or pd.isna(nuemp_ano2):\n",
    "        return False\n",
    "    if nuemp_ano1 != nuemp_ano2:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "for ano in range(9, 19):\n",
    "    ano_atual = f'nuemp_{ano:02d}'   \n",
    "    ano_proximo = f'nuemp_{ano + 1:02d}' \n",
    "    nova_coluna = f'mudou_emprego_{ano:02d}_{ano + 1:02d}'  \n",
    "\n",
    "    df_emp[nova_coluna] = df_emp.apply(lambda row: verifica_mudanca_emprego(row[ano_atual], row[ano_proximo]), axis=1)\n",
    "\n",
    "df_emp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b869e311-207f-4b06-81ff-0fd8b38865f0",
   "metadata": {},
   "source": [
    "- Análise da porporção de trocas de emprego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d310be1f-7b28-4dd3-baf2-4677d5331843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colunas_mudou_emprego = [col for col in df_emp.columns if col.startswith('mudou_emprego_')]\n",
    "\n",
    "for coluna in colunas_mudou_emprego:\n",
    "    contagem = df_emp[coluna].value_counts(dropna=False)\n",
    "    print(f'Contagem para a coluna {coluna}:')\n",
    "    print(contagem)\n",
    "    print()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a693b",
   "metadata": {},
   "source": [
    "## <font color='darkred'>Modelo de Regressão Logistica</font>\n",
    "### Variáveis Utilizadas no Modelo:\n",
    "- Mudou de Emprego;\n",
    "- Habilitações Literárias (habil1);\n",
    "- Tipo de Contrato;\n",
    "- Salário (rganho);\n",
    "- Cae (caem1l);\n",
    "- Profissão (prof_3d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02efd85f-6487-4e6a-b855-5fa73c9a7d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regr = df_emp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b487affa-cb10-46d2-b8cb-402d2b9b210b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "variaveis_interesse = ['habil1', 'tipo_contr1', 'prof_3d', 'rganho_h', 'caem1l']\n",
    "\n",
    "for ano in range(9, 19):\n",
    "    for var in variaveis_interesse:\n",
    "        col_atual = f'{var}_{ano:02d}'\n",
    "        col_anterior = f'{var}_{ano + 1:02d}'\n",
    "        nova_coluna = f'diff_{var}_{ano + 1:02d}'\n",
    "        df_regr[nova_coluna] = df_regr[col_anterior] - df_regr[col_atual]\n",
    "\n",
    "for ano in range(10, 20):\n",
    "    print(f\"\\nAvaliação para a mudança de {ano - 1} para {ano}\")\n",
    "    \n",
    "    # Definição das variáveis independentes (features) e dependentes (target)\n",
    "    variaveis_diferenca = [f'diff_{var}_{ano:02d}' for var in variaveis_interesse]\n",
    "    y = df_regr[f'mudou_emprego_{ano - 1:02d}_{ano:02d}']\n",
    "\n",
    "    X = df_regr[variaveis_diferenca]\n",
    "    \n",
    "    # Normalização de todas as variáveis independentes\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Conjunto de treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Avaliação do modelo\n",
    "    print(\"Matriz de Confusão:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nRelatório de Classificação:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Importância das features\n",
    "    importancia_features = pd.Series(model.coef_[0], index=variaveis_diferenca)\n",
    "    importancia_features = importancia_features.sort_values(ascending=False)\n",
    "    print(\"\\nImportância das Variáveis:\")\n",
    "    print(importancia_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38795fb6-034c-421c-9f9d-70af1c2060a5",
   "metadata": {},
   "source": [
    "De acordo com os resultados apresentados, é possível verificar que a classe True (mudança de emprego) é significativamente menor em relação à classe False (não mudança de emprego). Isto indica que estamos perante um desequilíbrio de classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f60aab-c464-4a6e-aa77-13a09780f80d",
   "metadata": {},
   "source": [
    "### <font color='darkred'> Melhorar o Desempenho do Modelo</font>\n",
    "#### 1º Método: SMOTE e Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc79df47-8931-4627-8ef7-d404c565764f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "variaveis_interesse = ['habil1', 'tipo_contr1', 'prof_3d', 'rganho_h', 'caem1l']\n",
    "\n",
    "for ano in range(9, 19):\n",
    "    for var in variaveis_interesse:\n",
    "        col_atual = f'{var}_{ano:02d}'\n",
    "        col_anterior = f'{var}_{ano + 1:02d}'\n",
    "        nova_coluna = f'diff_{var}_{ano + 1:02d}'\n",
    "        df_regr[nova_coluna] = df_regr[col_anterior] - df_regr[col_atual]\n",
    "\n",
    "for ano in range(10, 20):\n",
    "    print(f\"\\nAvaliação para a mudança de {ano - 1} para {ano}\")\n",
    "    \n",
    "    # Definição das variáveis independentes (features) e dependentes (target)\n",
    "    variaveis_diferenca = [f'diff_{var}_{ano:02d}' for var in variaveis_interesse]\n",
    "    y = df_regr[f'mudou_emprego_{ano - 1:02d}_{ano:02d}']\n",
    "\n",
    "    X = df_regr[variaveis_diferenca]\n",
    "    \n",
    "    # Normalização de todas as variáveis independentes\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Conjunto de treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # SMOTE para equilibar as classes no conjunto de treino\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Ajustar o modelo de regressão logística com pesos de classe\n",
    "    model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Avaliar o modelo\n",
    "    print(\"Matriz de Confusão:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nRelatório de Classificação:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Importância das features\n",
    "    importancia_features = pd.Series(model.coef_[0], index=variaveis_diferenca)\n",
    "    importancia_features = importancia_features.sort_values(ascending=False)\n",
    "    print(\"\\nImportância das Variáveis:\")\n",
    "    print(importancia_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6155f48-062b-4ec6-9d82-def7369b3d07",
   "metadata": {},
   "source": [
    "#### Conclusões do 1º Método\n",
    "- **Recall da Classe True:** O recall para a classe True melhorou consideravelmente em comparação com os resultados anteriores. Em vários anos, o recall ficou em torno de 0.50 ou superior, o que significa que o modelo está a considerar uma parte significativa dos casos de mudança de emprego.\n",
    "- **Precisão da Classe True:** A precisão para a classe True ainda é relativamente baixa, indicando que, embora o modelo esteja a identificar mais mudanças de emprego, ainda há uma quantidade significativa de falsos positivos.\n",
    "\n",
    "`Importância das Variáveis:`\n",
    "- **diff_habil1** e **diff_tipo_contr1:** Estas variáveis continuam a ser as mais importantes na maioria das avaliações, o que indica que mudanças na habilitação e no tipo de contrato são fatores significativos na previsão de mudanças de emprego."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9dfa3d-67a0-473e-bd72-579b6d10a434",
   "metadata": {},
   "source": [
    "### <font color='darkred'> Melhorar o Desempenho do Modelo</font>\n",
    "#### 2º Método: Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b3801-5088-446f-84a4-244ad3603154",
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_interesse = ['habil1', 'tipo_contr1', 'prof_3d', 'rganho_h', 'caem1l']\n",
    "\n",
    "for ano in range(9, 19):\n",
    "    for var in variaveis_interesse:\n",
    "        col_atual = f'{var}_{ano:02d}'\n",
    "        col_anterior = f'{var}_{ano + 1:02d}'\n",
    "        nova_coluna = f'diff_{var}_{ano + 1:02d}'\n",
    "        df_regr[nova_coluna] = df_regr[col_anterior] - df_regr[col_atual]\n",
    "\n",
    "for ano in range(10, 20):\n",
    "    print(f\"\\nAvaliação para a mudança de {ano - 1} para {ano}\")\n",
    "    \n",
    "    # Definição das variáveis independentes (features) e dependentes (target)\n",
    "    variaveis_diferenca = [f'diff_{var}_{ano:02d}' for var in variaveis_interesse]\n",
    "    y = df_regr[f'mudou_emprego_{ano - 1:02d}_{ano:02d}']\n",
    "\n",
    "    X = df_regr[variaveis_diferenca]\n",
    "    \n",
    "    # Normalizar todas as variáveis independentes\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Conjunto de treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # SMOTE para equilibar as classes no conjunto de treino\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Configurar o modelo de regressão logística regularizada (Ridge)\n",
    "    model = LogisticRegression(penalty='l2', max_iter=1000, class_weight='balanced')\n",
    "    \n",
    "    # Ajuste de hiperparâmetros usando GridSearchCV\n",
    "    param_grid = {'C': [0.01, 0.1, 1, 10, 100]}  # Valores de regularização a serem testados\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "    grid_search.fit(X_train_res, y_train_res)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Avaliar o modelo\n",
    "    print(f\"Melhor valor de C (Regularização): {grid_search.best_params_['C']}\")\n",
    "    print(\"Matriz de Confusão:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nRelatório de Classificação:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Importância das features\n",
    "    importancia_features = pd.Series(best_model.coef_[0], index=variaveis_diferenca)\n",
    "    importancia_features = importancia_features.sort_values(ascending=False)\n",
    "    print(\"\\nImportância das Variáveis:\")\n",
    "    print(importancia_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad51162-a7cf-4e09-beb3-77ccb6f880b4",
   "metadata": {},
   "source": [
    "## <font color='darkred'>Modelo de Random Forest</font>\n",
    "\n",
    "- O Random Forest, é um modelo não linear que constrói múltiplas árvores de decisão. Ele capta interações complexas entre variáveis que não seriam capturadas por um modelo linear.\n",
    "A importância das variáveis no Random Forest é medida com base no nº de vezes que uma variável é usada para dividir os dados nas árvores de decisão, e o impacto dessa divisão na redução da impureza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480bf06c-946e-4c57-bcf0-d50725263e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_interesse = ['habil1', 'tipo_contr1', 'prof_3d', 'rganho_h', 'caem1l']\n",
    "\n",
    "for ano in range(9, 19):\n",
    "    for var in variaveis_interesse:\n",
    "        col_atual = f'{var}_{ano:02d}'\n",
    "        col_anterior = f'{var}_{ano + 1:02d}'\n",
    "        nova_coluna = f'diff_{var}_{ano + 1:02d}'\n",
    "        df_regr[nova_coluna] = df_regr[col_anterior] - df_regr[col_atual]\n",
    "\n",
    "for ano in range(10, 20):\n",
    "    print(f\"\\nAvaliação para a mudança de {ano - 1} para {ano}\")\n",
    "    \n",
    "    # Definição das variáveis independentes (features) e dependentes (target)\n",
    "    variaveis_diferenca = [f'diff_{var}_{ano:02d}' for var in variaveis_interesse]\n",
    "    y = df_regr[f'mudou_emprego_{ano - 1:02d}_{ano:02d}']\n",
    "\n",
    "    X = df_regr[variaveis_diferenca]\n",
    "    \n",
    "    # Normalizar todas as variáveis independentes\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Conjunto de treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # SMOTE para equilibrar as classes no conjunto de treino\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Modelo RandomForest\n",
    "    model = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "    \n",
    "    # Hiperparâmetros com GridSearchCV\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "    \n",
    "    # Alternativamente, você pode usar RandomizedSearchCV para maior eficiência\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "    grid_search.fit(X_train_res, y_train_res)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Avaliar o modelo\n",
    "    print(f\"Melhores parâmetros encontrados: {grid_search.best_params_}\")\n",
    "    print(\"Matriz de Confusão:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nRelatório de Classificação:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Importância das features\n",
    "    importancia_features = pd.Series(best_model.feature_importances_, index=variaveis_diferenca)\n",
    "    importancia_features = importancia_features.sort_values(ascending=False)\n",
    "    print(\"\\nImportância das Variáveis:\")\n",
    "    print(importancia_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e748de-f343-4a99-94c4-bee54b25255d",
   "metadata": {},
   "source": [
    "#### Conclusões do Modelo:\n",
    "`Recall`\n",
    "\n",
    "Comparado com os modelos anteriores, o Random Forest conseguiu melhorar substancialmente o recall para a classe \"True\", o que indica que o modelo está identificando melhor as mudanças de emprego.\n",
    "Por exemplo, o recall varia de 0.64 a 0.76, o que é significativamente melhor do que os modelos de regressão logística, que tinham valores de recall muito baixos.\n",
    "\n",
    "`Precisão`\n",
    "\n",
    "A precisão para a classe \"True\" é menor (variando de 0.23 a 0.47), mas isto é expectável devido ao trade-off entre precisão e recall em problemas de classificação com classes desbalanceadas.\n",
    "\n",
    "`F1-score`\n",
    "\n",
    "A f1-score para a classe \"True\" também aumentou, indicando um melhor equilíbrio entre precisão e recall.\n",
    "\n",
    "`Importância das Variáveis`\n",
    "\n",
    "As variáveis mais importantes são **diff_prof_3d** (diferença na profissão), **diff_caem1l** (código de atividade económica), e **diff_rganho** (diferença nos ganhos). Isto significa que mudanças que mudanças na profissão, cae e remuneração são os principais fatores associados à troca de emprego."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a06ee-7668-4d74-9637-dd7fd6cec93d",
   "metadata": {},
   "source": [
    "## <font color='darkred'>Modelo LightGBM</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43606f21-d526-4e8a-910a-3f5ad8ca95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"lightgbm\").setLevel(logging.ERROR)\n",
    "\n",
    "variaveis_interesse = ['habil1', 'tipo_contr1', 'prof_3d', 'rganho_h', 'caem1l']\n",
    "\n",
    "for ano in range(9, 19):\n",
    "    for var in variaveis_interesse:\n",
    "        col_atual = f'{var}_{ano:02d}'\n",
    "        col_anterior = f'{var}_{ano + 1:02d}'\n",
    "        nova_coluna = f'diff_{var}_{ano + 1:02d}'\n",
    "        df_regr[nova_coluna] = df_regr[col_anterior] - df_regr[col_atual]\n",
    "\n",
    "for ano in range(10, 20):\n",
    "    print(f\"\\nAvaliação para a mudança de {ano - 1} para {ano}\")\n",
    "    \n",
    "    # Definir variáveis independentes (features) e dependentes (target) para o ano específico\n",
    "    variaveis_diferenca = [f'diff_{var}_{ano:02d}' for var in variaveis_interesse]\n",
    "    y = df_regr[f'mudou_emprego_{ano - 1:02d}_{ano:02d}']\n",
    "\n",
    "    X = df_regr[variaveis_diferenca]\n",
    "    \n",
    "    # Normalizar todas as variáveis independentes\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Conjunto de treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Configurar o modelo LightGBM\n",
    "    model = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        n_estimators=100,  \n",
    "        max_depth=5,       \n",
    "        learning_rate=0.1, \n",
    "        subsample=1.0,    \n",
    "        colsample_bytree=1.0,  \n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1  \n",
    "    )\n",
    "    \n",
    "    # Parâmetros para RandomizedSearchCV\n",
    "    param_dist = {\n",
    "        'num_leaves': [31, 50, 70],\n",
    "        'min_child_samples': [20, 50, 100],\n",
    "        'reg_alpha': [0, 0.1, 0.5],\n",
    "        'reg_lambda': [0, 0.1, 0.5],\n",
    "    }\n",
    "    \n",
    "    # RandomizedSearchCV para encontrar o melhor modelo\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        model, param_distributions=param_dist, n_iter=10, scoring='f1', cv=3, verbose=0, n_jobs=-1, random_state=42\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Avaliar o modelo\n",
    "    print(f\"Melhores parâmetros encontrados: {grid_search.best_params_}\")\n",
    "    print(\"Matriz de Confusão:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nRelatório de Classificação:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Importância das features\n",
    "    importancia_features = pd.Series(best_model.feature_importances_, index=variaveis_diferenca)\n",
    "    importancia_features = importancia_features.sort_values(ascending=False)\n",
    "    print(\"\\nImportância das Variáveis:\")\n",
    "    print(importancia_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d23de-1da6-4679-b1a3-cf5f76b978f2",
   "metadata": {},
   "source": [
    "## <font color='darkred'>Modelo LightGBM (Interações Polinomiais)</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b0615-c440-4852-94ef-5e5c721d52f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_interesse = ['habil1', 'tipo_contr1', 'prof_3d', 'rganho_h', 'caem1l']\n",
    "\n",
    "for ano in range(9, 19):\n",
    "    for var in variaveis_interesse:\n",
    "        col_atual = f'{var}_{ano:02d}'\n",
    "        col_anterior = f'{var}_{ano + 1:02d}'\n",
    "        nova_coluna = f'diff_{var}_{ano + 1:02d}'\n",
    "        df_regr[nova_coluna] = df_regr[col_anterior] - df_regr[col_atual]\n",
    "\n",
    "for ano in range(10, 20):\n",
    "    print(f\"\\nAvaliação para a mudança de {ano - 1} para {ano}\")\n",
    "    \n",
    "    # Definição das variáveis independentes (features) e dependentes (target)\n",
    "    variaveis_diferenca = [f'diff_{var}_{ano:02d}' for var in variaveis_interesse]\n",
    "    y = df_regr[f'mudou_emprego_{ano - 1:02d}_{ano:02d}']\n",
    "    X = df_regr[variaveis_diferenca]\n",
    "    \n",
    "    # Adicionar interações polinomiais\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    \n",
    "    # Normalizar todas as variáveis independentes\n",
    "    scaler = StandardScaler()\n",
    "    X_poly = scaler.fit_transform(X_poly)\n",
    "    \n",
    "    # Dividir dados em conjunto de treinamento e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Configurar o modelo LightGBM\n",
    "    model = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        subsample=1.0,\n",
    "        colsample_bytree=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    # Parâmetros para RandomizedSearchCV\n",
    "    param_dist = {\n",
    "        'num_leaves': [31, 50, 70, 150],\n",
    "        'min_child_samples': [10, 20, 50, 100],\n",
    "        'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
    "        'reg_lambda': [0, 0.1, 0.5, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    }\n",
    "    \n",
    "    # Stratified K-Fold Cross-Validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Otimização do modelo usando RandomizedSearchCV\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        model, param_distributions=param_dist, n_iter=10, scoring='f1', cv=skf, n_jobs=-1, random_state=42\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Melhor modelo encontrado\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Fazer previsões\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Avaliar o modelo\n",
    "    print(f\"Melhores parâmetros encontrados: {grid_search.best_params_}\")\n",
    "    print(\"Matriz de Confusão:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nRelatório de Classificação:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Importância das features\n",
    "    importancia_features = pd.Series(best_model.feature_importances_, index=poly.get_feature_names_out(variaveis_diferenca))\n",
    "    importancia_features = importancia_features.sort_values(ascending=False)\n",
    "    print(\"\\nImportância das Variáveis:\")\n",
    "    print(importancia_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a7b620-830d-4ff3-bf47-f0ded83ed110",
   "metadata": {},
   "source": [
    "---\n",
    "Beatriz Lapa - Tese de Mestrado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
